{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QES4J6Xk8ye3"
   },
   "source": [
    "## Edge detection :\n",
    "Every image has vertical and horizontal edges which actually combining to form a image. Convolution operation is used with some filters for detecting edges.\n",
    "\n",
    "We will try to do that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "colab_type": "code",
    "id": "gFqMiLvp92-4",
    "outputId": "fd4ddd1d-52ca-48d1-d9da-84d1b2d5df85"
   },
   "outputs": [],
   "source": [
    "# Read in the image\n",
    "image = io.imread(\"http://bigdeal.mu/wp-content/uploads/2019/02/324px-2018_BMW_420i_M_Sport_Automatic_2.0_Front.jpg\")\n",
    "plt.imshow(image)\n",
    "\n",
    "#\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "plt.imshow(gray, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "BSLmp0Cg-W-_",
    "outputId": "d008d445-c48c-428d-88bd-d2d9a495bdcd"
   },
   "outputs": [],
   "source": [
    "##Feel free to modify the numbers here, to try out another filter!\n",
    "filter = np.array([[-1, -1, 1, 1], [-1, -1, 1, 1], [-1, -1, 1, 1], [-1, -1, 1, 1]])\n",
    "\n",
    "print('Filter shape: ', filter.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "colab_type": "code",
    "id": "IVfUR5rv-eR3",
    "outputId": "c34ffe19-98c5-4088-d15e-83dbccc77721"
   },
   "outputs": [],
   "source": [
    "# Defining four different filters, \n",
    "# all of which are linear combinations of the `filter` defined above\n",
    "\n",
    "# define four filters\n",
    "filter_1 = filter\n",
    "filter_2 = filter_1.T\n",
    "filter_3 = -filter_1\n",
    "filter_4 = -filter_3\n",
    "filters = np.array([filter_1, filter_2, filter_3, filter_4])\n",
    "\n",
    "# For an example, print out the values of filter 1\n",
    "print('Filter 1: \\n', filter_1,'Filter 2: \\n', filter_2,'Filter 3: \\n', filter_3,'Filter 4: \\n', filter_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "UCn4suqv-vIR",
    "outputId": "d8f8db88-65e3-4a31-c62f-f59a74980a12"
   },
   "outputs": [],
   "source": [
    "# visualize all four filters \n",
    "# gives a great way to see what does the filters do\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(1, 4, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(filters[i], cmap='gray')\n",
    "    ax.set_title('Filter %s' % str(i+1))\n",
    "    width, height = filters[i].shape\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            ax.annotate(str(filters[i][x][y]), xy=(y,x),\n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center',\n",
    "                        color='white' if filters[i][x][y]<0 else 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OHauYJ3GAn2H"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "se5DG8EOAn-3"
   },
   "source": [
    "## Defining a convolutional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_fZtPUUSAn72"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "HRlqPpTD_8VK",
    "outputId": "0657d876-5114-484c-adcb-5c8e49186543"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "    \n",
    "# define a neural network with a single convolutional layer with four filters\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, weight):\n",
    "        super(Net, self).__init__()\n",
    "        # initializes the weights of the convolutional layer to be the weights of the 4 defined filters\n",
    "        k_height, k_width = weight.shape[2:]\n",
    "        # defines the convolutional layer, assumes there are 4 grayscale filters\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "        self.conv = nn.Conv2d(1, 4, kernel_size=(k_height, k_width), bias=False)\n",
    "        self.conv.weight = torch.nn.Parameter(weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # calculates the output of a convolutional layer\n",
    "        # pre- and post-activation\n",
    "        conv_x = self.conv(x)\n",
    "        activated_x = F.relu(conv_x)\n",
    "        \n",
    "        # returns both layers\n",
    "        return conv_x, activated_x\n",
    "    \n",
    "# instantiate the model and set the weights\n",
    "weight = torch.from_numpy(filters).unsqueeze(1).type(torch.FloatTensor)\n",
    "model = Net(weight)\n",
    "\n",
    "# print out the layer in the network\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ZGWnv1GA-XW"
   },
   "source": [
    "### We want now to visualise the image after it passed into a certain number of layers by defining this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4YFmw4VEBMRA"
   },
   "outputs": [],
   "source": [
    "# helper function for visualizing the output of a given layer\n",
    "# default number of filters is 4\n",
    "def viz_layer(layer, n_filters= 4):\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    \n",
    "    for i in range(n_filters):\n",
    "        ax = fig.add_subplot(1, n_filters, i+1, xticks=[], yticks=[])\n",
    "        # grab layer outputs\n",
    "        ax.imshow(np.squeeze(layer[0,i].data.numpy()), cmap='gray')\n",
    "        ax.set_title('Output %s' % str(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fA59Ze_GBaDf"
   },
   "source": [
    "### Now we visulaise the images after passing by eact filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dYMk6TTsBYdz",
    "outputId": "0b6ae49b-96be-4dd6-828e-68555de852a5"
   },
   "outputs": [],
   "source": [
    "# plot original image\n",
    "plt.imshow(gray, cmap='gray')\n",
    "\n",
    "# visualize all filters\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "fig.subplots_adjust(left=0, right=1.5, bottom=0.8, top=1, hspace=0.05, wspace=0.05)\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(1, 4, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(filters[i], cmap='gray')\n",
    "    ax.set_title('Filter %s' % str(i+1))\n",
    "\n",
    "    \n",
    "# convert the image into an input Tensor\n",
    "gray_img_tensor = torch.from_numpy(gray).unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "# get the convolutional layer (pre and post activation)\n",
    "conv_layer, activated_layer = model(gray_img_tensor.float())\n",
    "print(conv_layer)\n",
    "# visualize the output of a conv layer\n",
    "viz_layer(conv_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "313sI05PCRbB"
   },
   "source": [
    "## ** Activation Function\n",
    "Activation functions are mathematical equations that determine the output of a neural network.\n",
    "This function helps determines whether the neurons should be activated or not, based on whether each neuron’s input is relevant for the model’s prediction. \n",
    "Activation functions can be used to normlize the outputs.\n",
    "### Types of activation functions :\n",
    "\n",
    "\n",
    "*   Linear Activation Function\n",
    "*   **Non-Linear Activation Functions**\n",
    "\n",
    "### Why Non-Linear Activation Functions is used ?\n",
    "    - Non-Linear Activation Functions have a derivative,so they allow backpropagation\n",
    "    - They allow creating a deep neural network. \n",
    "### ReLU (Rectified Linear Unit):\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=192rGF8tZrCeBIK4bXZgUhWdN0zUy9gTW\">\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 781
    },
    "colab_type": "code",
    "id": "l10OV-RgCfgH",
    "outputId": "c5fcd086-9317-4ee4-f491-b95b15f4bc41"
   },
   "outputs": [],
   "source": [
    "# after a ReLu is applied\n",
    "print(activated_layer)\n",
    "viz_layer(activated_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c7L3PcO6LqzR"
   },
   "source": [
    "# Why Filters ?\n",
    "\n",
    "Convolutional neural networks apply a filter to an input to create a feature map that summarizes the presence of detected features in the input\n",
    "\n",
    "Convolutional neural networks do not learn a single filter; they, in fact, learn multiple features in parallel for a given input.\n",
    "\n",
    "\n",
    "Building a Convolutional layer:\n",
    "<img src=\"https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/convolutional-neural-networks/conv-visualization/notebook_ims/conv_layer.gif\" width=\"100%\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZLOro5bUPN6U"
   },
   "source": [
    "# 2.2- Pooling Layer\n",
    "Now we have as a result a stack of filtred image and more our images are complex the more filters we have, higher dimensionality means more computing ressourses to use and also can lead to **overfitting**.\n",
    "To reduce this dimentalinty we use pooling layer, one of the most used pooling layers is :\n",
    "### **Max-pool :**\n",
    "<img src=\"https://austingwalters.com/wp-content/uploads/2019/01/max-pooling.png\" width=\"50%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_QGFw9iOq2y"
   },
   "outputs": [],
   "source": [
    "#in the forward part\n",
    "self.pool = nn.MaxPool2d(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a40qaH1oO1MI"
   },
   "source": [
    "### Adding max pool layer in our model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 948
    },
    "colab_type": "code",
    "id": "lHdol1dDJhs9",
    "outputId": "9df7b453-ff44-440a-88ca-7030dfbae7ee"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, weight):\n",
    "        super(Net, self).__init__()\n",
    "        # initializes the weights of the convolutional layer to be the weights of the 4 defined filters\n",
    "        k_height, k_width = weight.shape[2:]\n",
    "        # defines the convolutional layer, assumes there are 4 grayscale filters\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "        self.conv = nn.Conv2d(1, 4, kernel_size=(k_height, k_width), bias=False)\n",
    "        # max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv.weight = torch.nn.Parameter(weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # calculates the output of a convolutional layer\n",
    "        # pre- and post-activation\n",
    "        convv=self.conv(x)\n",
    "        #Showing the size of the image after applying the conv layer \n",
    "        print(\"image shape after conv layer\",convv.shape)\n",
    "\n",
    "        conv_x = self.pool(convv)\n",
    "        #Showing the size of the image after applying the pool layer \n",
    "        print(\"image shape after max pool layer\",conv_x.shape)\n",
    "        activated_x = F.relu(conv_x)\n",
    "        \n",
    "        # returns both layers\n",
    "        return conv_x, activated_x\n",
    "# instantiate the model and set the weights\n",
    "\n",
    "weight = torch.from_numpy(filters).unsqueeze(1).type(torch.FloatTensor)\n",
    "print()\n",
    "model = Net(weight)\n",
    "\n",
    "# print out the layer in the network\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LM_HM-_jRd8a"
   },
   "source": [
    "### As a result :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "id": "YS3u8c_iRbqc",
    "outputId": "59f1cfaa-a59e-4a88-d886-6d525b72973c"
   },
   "outputs": [],
   "source": [
    "\n",
    "# plot original image\n",
    "plt.imshow(gray, cmap='gray')\n",
    "\n",
    "\n",
    "    \n",
    "# convert the image into an input Tensor\n",
    "gray_img_tensor = torch.from_numpy(gray).unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "# get the convolutional layer (pre and post activation)\n",
    "conv_layer, activated_layer = model(gray_img_tensor.float())\n",
    "\n",
    "# visualize the output of a conv layer\n",
    "viz_layer(activated_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j_NjT127Tz58"
   },
   "source": [
    "# 2.3- Fully connected Layer\n",
    "Now that we have converted our input image into a **feature level representaion**, we shall flatten the image into a column vector. The flattened output is fed to a feed-forward neural network and backpropagation applied to every iteration of training.\n",
    "### Forward propagation :\n",
    "### Backpropagation and computing gradients:\n",
    "<img src=\"https://www.researchgate.net/publication/303744090/figure/fig3/AS:368958596239360@1464977992159/Feedforward-Backpropagation-Neural-Network-architecture.png\" width=\"60%\">\n",
    "\n",
    "[image reference](https://journals.plos.org/plosone/article/figure?id=10.1371/journal.pone.0156338.g001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OYYmmtepIoOd"
   },
   "source": [
    "### At the end we will get a similar architecture :\n",
    "<img src=\"https://adeshpande3.github.io/assets/Cover.png\">\n",
    "\n",
    "[image reference](https://medium.com/datadriveninvestor/a-beginners-guide-to-convolutional-neural-networks-49384c75d1a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the code from this notebook is mainly taken from Udacity's introdution to pytorch.\n",
    "[here's the repo with all the code ](https://github.com/udacity/deep-learning-v2-pytorch)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "intro_CNNs_Solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
